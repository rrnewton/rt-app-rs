# How to Use rt-app-rs to Emulate a Workload

## Overview

rt-app-rs is a tool that can be used to emulate a use case. Not only the
sleep and run pattern can be emulated but also the dependency between tasks
like accessing same critical resources, creating sequential wake up or syncing
the wake up of threads. The use case is described in a JSON-like file which is
parsed and executed by rt-app-rs.

### Built-in JSON Preprocessor

rt-app-rs has a built-in JSON preprocessor that automatically handles several
relaxed-JSON conveniences, so no separate preprocessing step or external tool
is needed. The preprocessor provides the following features:

1. **C-style comments** -- You can annotate your configuration files with
   comments anywhere in the JSON. Both block comments (`/* ... */`) and
   line comments (`// ...`) are supported. Block comments can span multiple
   lines; line comments run from `//` to the end of the line. Comments
   inside quoted strings are left intact.

   ```json
   {
     /* This is a block comment */
     "duration": 5, // This is a line comment
     /*
      * Multi-line block comments
      * are also supported.
      */
     "calibration": "CPU0"
   }
   ```

2. **Trailing commas** before `}` or `]` -- A trailing comma after the last
   element of an object or array is silently removed, so you do not need to
   worry about keeping track of which element is last.

3. **Duplicate key deduplication** -- Keys appearing multiple times at the same
   object level are automatically renamed with numeric suffixes, e.g., `"run"`,
   `"run1"`, `"run2"`. This is especially useful when describing a sequence of
   the same kind of events (e.g., a sequence of multiple `run` and `sleep`
   events).

This means users can write natural, readable JSON without worrying about strict
JSON grammar rules or key uniqueness constraints.

## JSON File Skeleton

The JSON file that describes a workload is made of 3 main objects: `tasks`,
`resources`, and `global` objects. Only the `tasks` object is mandatory;
default values will be used if the `global` object is not defined. The
`resources` object is kept for backward compatibility with the original C
rt-app but it does not give any benefit to declare it as the resources are
now dynamically created by rt-app-rs when it parses the file.

## Global Object

The `global` object defines parameters for the whole use case:

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `duration` | Integer | Duration of the use case in seconds. All threads will be killed once the duration has elapsed. If `-1`, the use case will run indefinitely until all threads kill themselves (e.g., if a finite number of loops has been defined) or a signal is received. | `-1` |
| `calibration` | String or Integer | A string defines the CPU used to calibrate the ns-per-loop value (e.g., `"CPU0"`). An integer skips calibration and uses that value directly as ns per loop. | `"CPU0"` |
| `default_policy` | String | Default scheduling policy of threads. | `"SCHED_OTHER"` |
| `pi_enabled` | Boolean | Enable priority inheritance for mutexes. | `false` |
| `lock_pages` | Boolean | Lock memory pages in RAM. Prevents RT threads from stalling while a page is moved from swap. Only possible for non-CFS tasks. | `true` |
| `logdir` | String | Path to store the various log files. The directory must already exist. | `"./"` |
| `log_basename` | String | Prefix used for all log files. | `"rt-app"` |
| `log_size` | String or Integer | An integer defines a fixed size in MB of the temporary per-thread buffer for log data (circular buffer; oldest data lost on overflow). A string selects predefined behavior: `"file"` stores directly to file, `"Disable"` disables logging, `"Auto"` lets rt-app-rs compute the buffer size (not yet implemented; falls back to `"file"`). | `"file"` |
| `ftrace` | String | If not `"none"`, rt-app-rs logs events to ftrace for the requested categories (comma-separated list). See below for supported categories. | `"none"` |
| `gnuplot` | Boolean | If `true`, create gnuplot-compatible files for each thread. | `false` |
| `io_device` | String | Path to the file used for IO-bounded busy loops. **Specify carefully as it may damage the target file.** | `"/dev/null"` |
| `mem_buffer_size` | Integer | Size of the per-thread memory buffer in bytes for IO-bounded and memory-bounded busy loops. | `4194304` (4 MB) |
| `cumulative_slack` | Boolean | Accumulate slack measured during successive timer events in a phase. When `false`, reports the time between the end of the last event and the end of the phase. | `false` |

### Ftrace Categories

The `ftrace` parameter accepts a comma-separated list of the following category names:

- `main` -- events generated by the main rt-app-rs task
- `task` -- events generated by a task
- `run` -- events generated by the run of a task
- `loop` -- events generated by each loop of a task
- `stats` -- events reporting statistics on task activation

### Default Global Object

```json
{
    "global": {
        "duration": -1,
        "calibration": "CPU0",
        "default_policy": "SCHED_OTHER",
        "pi_enabled": false,
        "lock_pages": false,
        "logdir": "./",
        "log_size": "file",
        "log_basename": "rt-app",
        "ftrace": "none",
        "gnuplot": false,
        "io_device": "/dev/null",
        "mem_buffer_size": 4194304,
        "cumulative_slack": false
    }
}
```

## Tasks Object

The `tasks` object is made of sub-objects that describe threads. No other kind
of object than thread objects is allowed. The key value of each object will be
used as the thread's name.

```json
{
    "tasks": {
        "thread_name1": {
            ...
        },
        "thread_name2": {
            ...
        },
        "thread_name3": {
            ...
        }
    }
}
```

## Thread Object

A thread object describes the behavior of one kind of thread, meaning that
several threads can be created from the same object (see the `instance`
parameter below).

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `instance` | Integer | Number of threads to create with this thread object's properties. A value of `0` creates the internal structures but does not create a pthread. | `1` |
| `delay` | Integer | Initial delay before the thread starts execution, in microseconds. | `0` |
| `phases` | Object | Describes the behavior of the thread. This behavior can be split into several distinct phases with their own events and properties. See [Phase Object](#phase-object). | -- |

## Phase Object

If there is only one phase, the sequence of events can be directly placed in
the thread object instead of creating a `phases` object. For example, the two
objects below are equivalent:

```json
{
    "tasks": {
        "thread1": {
            "phases": {
                "phase1": {
                    "run": 10,
                    "sleep": 10
                }
            }
        }
    }
}
```

```json
{
    "tasks": {
        "thread1": {
            "run": 10,
            "sleep": 10
        }
    }
}
```

## Thread and Phase Object Properties

Several properties can be set at the thread and/or phase level. All these
properties are optional and default values will be used if nothing is defined.

### Loop

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `loop` | Integer | Number of times the parent object must be run. For a phase, this is the number of times the phase executes before starting the next phase. For a thread, this is the number of times the complete `phases` object is executed. | `-1` (thread), `1` (phase) |

## Scheduling Policy

The scheduling policy can be set at thread and phase levels. A default policy
is applied after thread creation if nothing has been defined. The scheduling
properties can be changed at the beginning of each phase if defined in the
phase object. The behavior is similar to an event: an update happens only if
one of the scheduling parameters has been set; otherwise the scheduling
parameters remain unchanged.

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `policy` | String | Scheduling policy. Accepted values: `"SCHED_OTHER"`, `"SCHED_IDLE"`, `"SCHED_RR"`, `"SCHED_FIFO"`, `"SCHED_DEADLINE"`. | `default_policy` from global |
| `priority` | Integer | Scheduling priority. Must be within the range allowed by the policy. | `0` for `SCHED_OTHER`/`SCHED_DEADLINE`, `10` for RT classes |
| `dl-runtime` | Integer | Runtime budget for deadline scheduling class, in microseconds. Since Linux 6.12, this also applies to `SCHED_OTHER` to request a custom slice length. For backward compatibility, the key `"runtime"` is also checked in thread objects (but take care as this can conflict with the `runtime` event). | `0` |
| `dl-period` | Integer | Period duration for deadline scheduling class, in microseconds. For backward compatibility, `"period"` is also checked. | Same as `dl-runtime` |
| `dl-deadline` | Integer | Deadline parameter for deadline scheduling class, in microseconds. For backward compatibility, `"deadline"` is also checked. | Same as `dl-period` |

## CPU Affinity

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `cpus` | Array of Integer | CPU affinity for the thread. Can be specified at the task level or phase level. | All CPUs |

Example: the configuration below creates two threads. The first thread runs
with affinity to CPUs 2 and 3. The second thread runs its first phase with
affinity to CPUs 0 and 1, its second phase with affinity to CPU 2, and its
third phase inherits the task-level affinity of CPUs 4, 5, and 6:

```json
{
    "tasks": {
        "thread1": {
            "cpus": [2, 3],
            "phases": {
                "phase1": {
                    "run": 10,
                    "sleep": 10
                }
            }
        },
        "thread2": {
            "cpus": [4, 5, 6],
            "phases": {
                "phase1": {
                    "cpus": [0, 1],
                    "run": 10,
                    "sleep": 10
                },
                "phase2": {
                    "cpus": [2],
                    "run": 10,
                    "sleep": 10
                },
                "phase3": {
                    "run": 10,
                    "sleep": 10
                }
            }
        }
    }
}
```

## Utilization Clamping

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `util_min` | Integer | Minimum utilization value for the task; helps boost the task from the scheduler's point of view. Can be specified at task or phase level. | -- |
| `util_max` | Integer | Maximum utilization value for the task; helps cap the task from the scheduler's point of view. Can be specified at task or phase level. | -- |

## NUMA Memory Binding

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `nodes_membind` | Array of Integer | NUMA memory binding for the thread. Can be specified at task or phase level. rt-app-rs follows an event-based policy: it changes memory binding when there is a `nodes_membind` event and does nothing otherwise. | All NUMA nodes |

Example: the configuration below creates two threads. The first thread runs
with memory binding to nodes 2 and 3. The second thread runs its first phase
with memory binding to nodes 0 and 1, and its second phase with memory binding
to node 2:

```json
{
    "tasks": {
        "thread1": {
            "nodes_membind": [2, 3],
            "phases": {
                "phase1": {
                    "run": 10,
                    "sleep": 10
                }
            }
        },
        "thread2": {
            "phases": {
                "phase1": {
                    "nodes_membind": [0, 1],
                    "run": 10,
                    "sleep": 10
                },
                "phase2": {
                    "nodes_membind": [2],
                    "run": 10,
                    "sleep": 10
                }
            }
        }
    }
}
```

## Task Groups

| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `taskgroup` | String | Can be specified at task or phase level. Currently only `SCHED_OTHER` and `SCHED_IDLE` tasks are supported. Tasks with a different policy and without taskgroup data can coexist. An empty string (`""`) is interpreted as no taskgroup data. Pre-existing parts of a taskgroup are preserved and not removed during teardown. | -- |

The default build supports up to 32 different taskgroups. If a configuration
exceeds this limit, an error is reported before rt-app-rs exits.

## Events

Events are simple actions performed by or on a thread. They must be listed in
execution order.

### `run`

**Type:** Integer (microseconds)

Emulate the execution of a fixed workload. The `run` event runs a calibrated
loop that wastes CPU cycles. When executed with parameter `t`, the workload is:

```
n := floor(t * 1000 / pLoad)
```

where `pLoad` is the calibrated ns-per-loop value. This emulates a fixed
workload whose duration varies with CPU frequency or compute capacity.

### `runtime`

**Type:** Integer (microseconds)

Similar to `run`, but runs for a specific wall-clock amount of time
irrespective of CPU compute capacity or frequency.

### `sleep`

**Type:** Integer (microseconds)

Emulate the sleep of a task.

### `mem`

**Type:** Integer (bytes)

Emulate a memory write operation. The value defines the number of bytes to
write into the memory buffer (whose size is set by `mem_buffer_size` in the
`global` object).

### `iorun`

**Type:** Integer (bytes)

Emulate an IO write operation. The value defines the number of bytes to write
to the IO device specified by `io_device` in the `global` object.

### `timer`

**Type:** Object

Emulate the wake up of a thread by a timer. A `timer` differs from `sleep` in
when the duration starts counting. A `sleep` duration starts at the beginning
of the sleep event, whereas a `timer` duration starts at the end of the last
use of the timer. This makes timer events immune to preemption, frequency
scaling, and varying CPU compute capacity. The initial starting time is set
during the first use of the timer.

```
          |<------19---------->|<------19---------->|<------19---------->|
task A ...|run 5|timer 19      |------run 5|timer 19|run 5|timer 19      |
task B                      |run 10  |
```

#### Timer vs. Sleep Example

Consider a task A that runs 5 then sleeps 10 (period should be 15), and a
task B that runs 5 and uses a timer to wake up every 19:

```
         |<------15------>|<------15------>|<------19---------->|
taskA ...|run 5|sleep 10  |run 5|sleep 10  |----run 5|sleep 10  |...
taskB ...|------run 5|timer 19|--run 5|timer 19    |run 5|timer 19 |...
         |<------19---------->|<------19---------->|<------19---------->|
```

Task B's period stays at 19 even when the run event is delayed by scheduling
preemption, whereas task A's period starts at 15 but increases to 19 because
of the scheduling delay.

#### Unique Timers

When a thread that uses a timer is instantiated with multiple instances, the
timer is shared across instances, which disturbs the original sequence. To
create one timer per instance, use the `"unique"` prefix so a new timer will
be created for each instance. Uniqueness applies at the thread boundary: using
the same unique name within a thread's sequence refers to the same timer:

```json
{
    "phases": {
        "light": {
            "loop": 10,
            "run": 1000,
            "timer": { "ref": "unique", "period": 30000 }
        },
        "heavy": {
            "loop": 10,
            "run": 4000,
            "timer": { "ref": "unique", "period": 30000 }
        }
    }
}
```

To refer to different timers, use different names:

```json
{
    "phases": {
        "light": {
            "loop": 10,
            "run": 1000,
            "timer": { "ref": "uniqueA", "period": 30000 }
        },
        "heavy": {
            "loop": 10,
            "run": 4000,
            "timer": { "ref": "uniqueB", "period": 400000 }
        }
    }
}
```

#### Timer Modes: Relative vs. Absolute

Timers can work in `"relative"` or `"absolute"` mode. The default is
`"relative"`.

**Relative mode** (`"mode": "relative"`): The reference for the next timer
event is relative to the end of the current phase. If events in a phase took
too long and the timer missed, the next phase is not affected:

```json
{
    "phases": {
        "phase0": {
            "loop": 10,
            "run0": 10000,
            "timer0": { "ref": "unique", "period": 20000, "mode": "relative" }
        }
    }
}
```

```
  +-----+     +-----+     +-------------------+-----+     +---
  |r0   |     |r0   |     |r0                 |r0   |     |r0
  |     |     |     |     |                   |     |     |
  o-----------o-----------o-------------------o-----------o------->
  0    10    20    30    40    50    60    70    80   100   120
              ^           ^           ^                   ^
              |           |           | MISS!             |
            Timer0      Timer0      Timer0             Timer0
```

The third activation of Timer0 is missed since `r0` ran for more than 20 ms.
However the next phase is unaffected because Timer0 was set relative to when
the misbehaving `r0` finished.

**Absolute mode** (`"mode": "absolute"`): The reference is fixed and always
considers the starting time of the first phase. If a phase overruns, subsequent
phases _will_ be affected:

```json
{
    "phases": {
        "phase0": {
            "loop": 10,
            "run0": 10000,
            "timer0": { "ref": "unique", "period": 20000, "mode": "absolute" }
        }
    }
}
```

```
  +-----+     +-----+     +-------------------+-----+-----+   +---
  |r0   |     |r0   |     |r0                 |r0   |r0   |   |r0
  |     |     |     |     |                   |     |     |   |
  o-----------o-----------o-------------------o-----o---------o---->
  0    10    20    30    40    50    60    70    80   100   120
              ^           ^           ^           ^           ^
              |           |           | MISS!     | MISS!     |
            Timer0      Timer0      Timer0     Timer0      Timer0
```

The third Timer0 is missed because `r0` overran. Even though the fourth `r0`
runs for the specified 10 ms, the fourth Timer0 is still missed because the
absolute reference did not change.

### `lock`

**Type:** String

Lock the mutex identified by the string value.

### `unlock`

**Type:** String

Unlock the mutex identified by the string value.

### `wait`

**Type:** Object `{"ref": "<name>", "mutex": "<name>"}`

Block the calling thread until another thread sends a wake-up signal to the
resource defined by `"ref"`. The mutex defined by `"mutex"` is used during the
block sequence. See `pthread_cond_wait()` for details about the sequence
(especially regarding mutex usage).

### `signal`

**Type:** String

Send a wake-up signal to the resource identified by the string. The first
thread in the wait list will be woken up. See `pthread_cond_signal()` for
details.

### `broad`

**Type:** String

Send a wake-up signal to the resource identified by the string. All threads
blocked on the resource will wake up. See `pthread_cond_broadcast()` for
details.

### `sync`

**Type:** Object `{"ref": "<name>", "mutex": "<name>"}`

Atomically wake up a blocked thread and then block the calling thread on the
condition.

```
taskA ...|run 5|wait|------------|run 5| wait |----------------
taskB ...-------------------|sync|--------
```

The sync event `"sync": {"ref": "CondA", "mutex": "mutexA"}` generates the
following sequence:

```json
{
    "lock": "mutexA",
    "signal": "CondA",
    "wait": { "ref": "condA", "mutex": "mutexA" },
    "unlock": "mutexA"
}
```

### `barrier`

**Type:** String

Used as at least a pair where the name must match. Any number of matching uses
will cause all threads hitting the barrier event to wait for a signal. The
number of users is recorded, so when the last user hits the barrier event, that
thread will broadcast and all continue to the next step. This is conceptually
the same as `pthread_barrier_wait`, but implemented differently to allow more
flexible cleanup behavior.

You must use a unique name for each sync point since the number of users is
determined from the number of references to that name in the input JSON. Each
name must represent a single sync point shared among all threads that wish to
synchronize at that point.

> **Note:** `barrier` cannot be used with the `fork` event because the number
> of waiting threads must be known in advance, which is not possible with
> forked events.

The barrier event `"barrier": "SyncPointA"` generates the following sequence:

```
lock "SyncPointA" (internal mutex)
if shared variable is 0:
    signal "SyncPointA" (internal condvar)
else:
    decrement shared variable
    wait on "SyncPointA" (internal condvar + mutex)
    increment shared variable
unlock "SyncPointA" (internal mutex)
```

### `suspend`

**Type:** String

Block the calling thread until another thread wakes it up with `resume`. The
string value is ignored.

### `resume`

**Type:** String

Wake up the thread identified by the string.

```
taskA ...|run 5|suspend |----------------|run 5|suspend |----------------
taskB ...-------------------|resume taskA|run 10    |--------------------
```

### `yield`

**Type:** String

Calls `pthread_yield()`, freeing the CPU for other tasks. This has a special
meaning for `SCHED_DEADLINE` tasks. The string can be empty.

### `fork`

**Type:** String

Instead of creating all tasks at start time, you can fork one at any point
using this event. The name of the forked task must match one of the defined
tasks.

## Trace and Log

Traces and log hooks are available to ease debugging and monitor various
metrics of the use cases.

### Ftrace Tracing

A trace can be inserted into the ftrace buffer for each event in order to
synchronize kernel events like `sched_switch` with the use case's sequence.

Example ftrace log:

```
      rt-app-22165 [002] 105512.816244: print: tracking_mark_write: rtapp_main: event=start
small_task-0-22166 [005] 105512.839499: print: tracking_mark_write: rtapp_main: event=clock_ref data=105512715874
small_task-0-22166 [005] 105512.851733: print: tracking_mark_write: rtapp_task: event=start
small_task-0-22166 [001] 105512.852153: print: tracking_mark_write: rtapp_loop: event=start thread_loop=0 phase=0 phase_loop=0
small_task-0-22166 [001] 105512.852164: print: tracking_mark_write: rtapp_event: id=0 type=6 desc=run
small_task-0-22166 [001] 105512.853565: print: tracking_mark_write: rtapp_event: id=1 type=10 desc=timer:small_task
small_task-0-22166 [001] 105512.853585: print: tracking_mark_write: rtapp_loop: event=end thread_loop=0 phase=0 phase_loop=0
small_task-0-22166 [001] 105512.853592: print: tracking_mark_write: rtapp_loop: event=start thread_loop=0 phase=0 phase_loop=1
small_task-0-22166 [001] 105512.853600: print: tracking_mark_write: rtapp_event: id=0 type=6 desc=run
small_task-0-22166 [001] 105512.854999: print: tracking_mark_write: rtapp_event: id=1 type=10 desc=timer:small_task
  big_task-1-22167 [000] 105512.855414: print: tracking_mark_write: rtapp_task: event=start
  big_task-1-22167 [001] 105512.855723: print: tracking_mark_write: rtapp_loop: event=start thread_loop=0 phase=0 phase_loop=0
  big_task-1-22167 [001] 105512.855732: print: tracking_mark_write: rtapp_event: id=0 type=6 desc=run
  big_task-1-22167 [001] 105512.862754: print: tracking_mark_write: rtapp_event: id=1 type=10 desc=timer:big_task
```

### Task Name Format in Traces

The task index is encoded in the task name following this template:

```
<task_name>-<task_id>[-<fork_id>]-<pid>
```

| Field | Description |
|-------|-------------|
| `task_name` | Name of the task as specified in the task definition |
| `task_id` | ID of the task matching its position in the JSON file |
| `fork_id` | ID of the nth forked version of a task (optional; only for forked tasks) |
| `pid` | Linux-assigned PID for this task |

### Trace Event Categories

#### Main task events

```
rtapp_main: event=start
rtapp_main: event=clock_ref data=105512715874
rtapp_main: event=end
```

Reporting the start and end of the main thread. The `clock_ref` event
back-annotates in the trace the time reference used by performance log entries.

#### Workload task events

```
rtapp_task: event=start
rtapp_task: event=end
```

Reporting the start and end of worker tasks.

#### Loop events

```
rtapp_loop: event=start thread_loop=0 phase=0 phase_loop=0
rtapp_loop: event=end thread_loop=0 phase=0 phase_loop=0
```

Reporting the start and end of workload phases and loops.

#### Workload events

```
rtapp_event: id=0 type=6 desc=run
rtapp_event: id=1 type=10 desc=timer:small_task
```

Reporting the execution of the specified event type in the current phase/loop.

#### Stats events

```
rtapp_stats: period=3948 run=1378 wu_lat=95 slack=2454 c_run=16000 c_period=1600
```

Reporting the major performance metrics measured after each workload activation.

### Log and Gnuplot

You can log metrics for each phase executed by a thread. The available metrics
are:

| Metric | Description |
|--------|-------------|
| `perf` | Fixed amount of work performed during a phase (`c_duration / calibration`). Measured in units of 1000 loops, each of `pLoad` ns. |
| `run` | Time spent executing run events (microseconds). |
| `period` | Duration to execute the complete phase (microseconds). |
| `start` / `end` | Absolute start and end time of a phase. Uses the same time base as ftrace. |
| `rel_st` | Start time of a phase relative to the beginning of the use case. |
| `slack` | See below for details. |
| `c_duration` | Sum of the configured duration of `run`/`runtime` events (microseconds). |
| `c_period` | Sum of the timer period(s) (microseconds). |
| `wu_lat` | Sum of wakeup latencies after timer events (microseconds). |

#### Slack

If the global option `cumulative_slack` is `false` (default), slack is the time
between the end of the last event and the end of the phase:

```
taskA ...|-- run5 --|- sleep5 -|-- run5--|..timer20.|-- run5 --|- sleep5 -|-- run6 --|.timer20.|
          <--------------- period 20 --------------> <--------------- period 20 -------------->
                                          <-slack5->                                  <slack4->
```

Slack can be negative if execution of a phase's events overshoots the current
period:

```
taskA ...|-- run5 --|- sleep5 -|------- run30 ------xxxxxxxxxx|
          <--------------- period 20 -------------->
                                                     <slack-5>
```

If `cumulative_slack` is `true`, all intermediate slacks of a phase with
multiple timers are accumulated and reported when the phase completes.

#### Example Log Output

```
# Policy : SCHED_OTHER priority : 0
#idx     perf      run   period           start             end          rel_st      slack c_duration   c_period     wu_lat
   0    92164    19935    98965    504549567051    504549666016            2443      78701      20000     100000        266
   0    92164    19408    99952    504549666063    504549766015          101455      80217      20000     100000        265
   0    92164    19428    99952    504549766062    504549866014          201454      80199      20000     100000        264
   0    92164    19438    99955    504549866060    504549966015          301452      80190      20000     100000        265
   0    92164    19446    99952    504549966061    504550066013          401453      80093      20000     100000        264
   0    92164    19415    99953    504550066060    504550166013          501452      80215      20000     100000        263
   0    92164    19388    99954    504550166059    504550266013          601451      80242      20000     100000        264
   0    92164    19444    99956    504550266060    504550366015          701452      80185      20000     100000        265
```

When `gnuplot` is enabled, gnuplot-compatible files are also created to
generate charts based on the log files for each thread and each kind of metric.
The output format is EPS.
